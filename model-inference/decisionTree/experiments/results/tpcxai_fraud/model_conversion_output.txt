nohup: ignoring input
2022-09-11 18:36:40.385874: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/ubuntu/libtorch/lib:/home/ubuntu/libtorch/lib:
2022-09-11 18:36:40.385926: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2022-09-11 18:36:42.030680: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/ubuntu/libtorch/lib:/home/ubuntu/libtorch/lib:
2022-09-11 18:36:42.030724: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2022-09-11 18:36:42.030749: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-172-31-95-108): /proc/driver/nvidia/version does not exist
2022-09-11 18:36:42.030969: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
DATASET: tpcxai_fraud
MODEL: randomforest
FRAMEWORKS: pytorch,torch,tf-df,onnx,netsdb
------------------------------
Converting model to PyTorch...
------------------------------
Time Taken to convert HummingbirdPyTorch: 31.015872955322266
Time taken to save pytorch model 3.6551952362060547
------------------------------
Converted model to PyTorch
------------------------------


------------------------------
Converting model to Torch...
------------------------------
Time taken to convert to torch using hummingbird 5.460977554321289
Time taken to save torch model 1.653909683227539
------------------------------
Converted model to Torch
------------------------------


------------------------------
Converting model to TF-DF...
------------------------------
Use /tmp/tmpp7ajal48 as temporary training directory
[INFO kernel.cc:1176] Loading model from path intermediate_path/tmp/ with prefix 17c3deda07214435
[INFO kernel.cc:1028] Use slow generic engine
WARNING:tensorflow:AutoGraph could not transform <function simple_ml_inference_op_with_handle at 0x7fd2c75dd0d0> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: could not get source code
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
WARNING:tensorflow:AutoGraph could not transform <function simple_ml_inference_op_with_handle at 0x7fd2c75dd0d0> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: could not get source code
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
WARNING:absl:Found untraced functions such as call_get_leaves while saving (showing 1 of 1). These functions will not be directly callable after loading.
[INFO kernel.cc:1176] Loading model from path intermediate_path/assets/ with prefix 17c3deda07214435
[INFO kernel.cc:1028] Use slow generic engine
WARNING:absl:Found untraced functions such as restored_function_body while saving (showing 1 of 1). These functions will not be directly callable after loading.
Time taken to save tfdf randomforest model 4017.674446105957
------------------------------
Converted model to TF-DF
------------------------------


------------------------------
Converting model to ONNX...
------------------------------
Time taken to convert onnx using hummingbird 12.90750503540039
Time taken to write onnx model 0.3190040588378906
------------------------------
Converted model to ONNX
------------------------------


------------------------------
Converting model to netsdb...
------------------------------
------------------------------
Converted model to netsdb
------------------------------


2022-09-11 18:36:50.288325: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/ubuntu/libtorch/lib:/home/ubuntu/libtorch/lib:
2022-09-11 18:36:50.288397: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2022-09-11 18:36:51.934939: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/ubuntu/libtorch/lib:/home/ubuntu/libtorch/lib:
2022-09-11 18:36:51.934993: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2022-09-11 18:36:51.935030: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-172-31-95-108): /proc/driver/nvidia/version does not exist
2022-09-11 18:36:51.935272: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
DATASET: tpcxai_fraud
MODEL: xgboost
FRAMEWORKS: pytorch,torch,tf-df,onnx,treelite,netsdb
------------------------------
Converting model to PyTorch...
------------------------------
Time Taken to convert HummingbirdPyTorch: 44.26765441894531
Time taken to save pytorch model 2.5568008422851562
------------------------------
Converted model to PyTorch
------------------------------


------------------------------
Converting model to Torch...
------------------------------
Time taken to convert to torch using hummingbird 18.045425415039062
Time taken to save torch model 1.2416839599609375
------------------------------
Converted model to Torch
------------------------------


------------------------------
Converting model to TF-DF...
------------------------------
XGBOOST_MODEL LEARNING RATE:
0.1
Use /tmp/tmpkamzsc_b as temporary training directory
[INFO kernel.cc:1176] Loading model from path intermediate_path/tmp/ with prefix 84731e807455458b
[INFO kernel.cc:1028] Use slow generic engine
WARNING:tensorflow:AutoGraph could not transform <function simple_ml_inference_op_with_handle at 0x7f3a503ac0d0> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: could not get source code
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
WARNING:tensorflow:AutoGraph could not transform <function simple_ml_inference_op_with_handle at 0x7f3a503ac0d0> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: could not get source code
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
WARNING:absl:Found untraced functions such as call_get_leaves while saving (showing 1 of 1). These functions will not be directly callable after loading.
[INFO kernel.cc:1176] Loading model from path intermediate_path/assets/ with prefix 84731e807455458b
[INFO kernel.cc:1028] Use slow generic engine
WARNING:absl:Found untraced functions such as restored_function_body while saving (showing 1 of 1). These functions will not be directly callable after loading.
Time taken to save tfdf xgboost model 3743.692636489868
------------------------------
Converted model to TF-DF
------------------------------


------------------------------
Converting model to ONNX...
------------------------------
Time taken to convert onnx using hummingbird 20.630598068237305
Time taken to write onnx model 0.2644062042236328
------------------------------
Converted model to ONNX
------------------------------


------------------------------
Converting model to TreeLite...
------------------------------
[18:36:55] ../src/compiler/ast_native.cc:711: Using ASTNativeCompiler
[18:36:55] ../src/compiler/ast/split.cc:29: Parallel compilation enabled; member trees will be divided into 8 translation units.
[18:36:55] ../src/c_api/c_api.cc:92: Code generation finished. Writing code to files...
[18:36:55] ../src/c_api/c_api.cc:97: Writing file recipe.json...
[18:36:55] ../src/c_api/c_api.cc:97: Writing file tu4.c...
[18:36:55] ../src/c_api/c_api.cc:97: Writing file tu3.c...
[18:36:55] ../src/c_api/c_api.cc:97: Writing file header.h...
[18:36:55] ../src/c_api/c_api.cc:97: Writing file main.c...
[18:36:55] ../src/c_api/c_api.cc:97: Writing file tu0.c...
[18:36:55] ../src/c_api/c_api.cc:97: Writing file tu1.c...
[18:36:55] ../src/c_api/c_api.cc:97: Writing file tu2.c...
[18:36:55] /home/ubuntu/.local/lib/python3.9/site-packages/treelite/contrib/util.py:105: Compiling sources files in directory /home/ubuntu/netsdb/model-inference/decisionTree/experiments/models/tmpo3d7n2o3 into object files (*.o)...
[18:36:55] /home/ubuntu/.local/lib/python3.9/site-packages/treelite/contrib/util.py:135: Generating dynamic shared library /home/ubuntu/netsdb/model-inference/decisionTree/experiments/models/tmpo3d7n2o3/predictor.so...
[18:36:55] /home/ubuntu/.local/lib/python3.9/site-packages/treelite/contrib/__init__.py:282: Generated shared library in 0.18 seconds
Time taken to convert and write treelite model 200.35910606384277
------------------------------
Converted model to TreeLite
------------------------------


------------------------------
Converting model to netsdb...
------------------------------
------------------------------
Converted model to netsdb
------------------------------


The maximum opset needed by this model is only 9.
DATASET: tpcxai_fraud
MODEL: lightgbm
FRAMEWORKS: pytorch,torch,onnx,treelite,lleaves,netsdb
------------------------------
Converting model to PyTorch...
------------------------------
Time Taken to convert HummingbirdPyTorch: 29.998302459716797
Time taken to save pytorch model 3.168821334838867
------------------------------
Converted model to PyTorch
------------------------------


------------------------------
Converting model to Torch...
------------------------------
Time taken to convert to torch using hummingbird 6.263256072998047
Time taken to save torch model 1.2505054473876953
------------------------------
Converted model to Torch
------------------------------


------------------------------
Converting model to ONNX...
------------------------------
Time taken to convert onnx using onnxmltools 9.741783142089844
Time taken to write onnx model 0.3104209899902344
------------------------------
Converted model to ONNX
------------------------------


------------------------------
Converting model to TreeLite...
------------------------------
[18:36:59] ../src/compiler/ast_native.cc:711: Using ASTNativeCompiler
[18:36:59] ../src/compiler/ast/split.cc:29: Parallel compilation enabled; member trees will be divided into 8 translation units.
[18:36:59] ../src/c_api/c_api.cc:92: Code generation finished. Writing code to files...
[18:36:59] ../src/c_api/c_api.cc:97: Writing file recipe.json...
[18:36:59] ../src/c_api/c_api.cc:97: Writing file tu4.c...
[18:36:59] ../src/c_api/c_api.cc:97: Writing file tu3.c...
[18:36:59] ../src/c_api/c_api.cc:97: Writing file header.h...
[18:36:59] ../src/c_api/c_api.cc:97: Writing file main.c...
[18:36:59] ../src/c_api/c_api.cc:97: Writing file tu0.c...
[18:36:59] ../src/c_api/c_api.cc:97: Writing file tu1.c...
[18:36:59] ../src/c_api/c_api.cc:97: Writing file tu2.c...
[18:36:59] /home/ubuntu/.local/lib/python3.9/site-packages/treelite/contrib/util.py:105: Compiling sources files in directory /home/ubuntu/netsdb/model-inference/decisionTree/experiments/models/tmpu1_sda09 into object files (*.o)...
[18:37:00] /home/ubuntu/.local/lib/python3.9/site-packages/treelite/contrib/util.py:135: Generating dynamic shared library /home/ubuntu/netsdb/model-inference/decisionTree/experiments/models/tmpu1_sda09/predictor.so...
[18:37:00] /home/ubuntu/.local/lib/python3.9/site-packages/treelite/contrib/__init__.py:282: Generated shared library in 0.16 seconds
Time taken to convert and write treelite model 179.51083183288574
------------------------------
Converted model to TreeLite
------------------------------


------------------------------
Converting model to Lleaves...
------------------------------
Time taken to convert, compile and write Lleaves model 3.10516357421875
------------------------------
Converted model to Lleaves
------------------------------


------------------------------
Converting model to netsdb...
------------------------------
------------------------------
Converted model to netsdb
------------------------------


2022-09-11 18:37:08.678561: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/ubuntu/libtorch/lib:/home/ubuntu/libtorch/lib:
2022-09-11 18:37:08.678610: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2022-09-11 18:37:21.983683: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/ubuntu/libtorch/lib:/home/ubuntu/libtorch/lib:
2022-09-11 18:37:21.983732: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2022-09-11 18:37:21.983759: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-172-31-95-108): /proc/driver/nvidia/version does not exist
2022-09-11 18:37:21.983989: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
DATASET: tpcxai_fraud
MODEL: randomforest
FRAMEWORKS: pytorch,torch,tf-df,onnx,netsdb
------------------------------
Converting model to PyTorch...
------------------------------
Time Taken to convert HummingbirdPyTorch: 2324.896812438965
Time taken to save pytorch model 99.4575023651123
------------------------------
Converted model to PyTorch
------------------------------


------------------------------
Converting model to Torch...
------------------------------
Time taken to convert to torch using hummingbird 2134.538412094116
Time taken to save torch model 5.615472793579102
------------------------------
Converted model to Torch
------------------------------


------------------------------
Converting model to TF-DF...
------------------------------
Use /tmp/tmpo56hpspf as temporary training directory
[INFO kernel.cc:1176] Loading model from path intermediate_path/tmp/ with prefix 983c5509ae744d96
[INFO decision_forest.cc:639] Model loaded with 500 root(s), 150490 node(s), and 6 input feature(s).
[INFO abstract_model.cc:1246] Engine "RandomForestOptPred" built
[INFO kernel.cc:1022] Use fast generic engine
WARNING:tensorflow:AutoGraph could not transform <function simple_ml_inference_op_with_handle at 0x7f53a1935550> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: could not get source code
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
WARNING:tensorflow:AutoGraph could not transform <function simple_ml_inference_op_with_handle at 0x7f53a1935550> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: could not get source code
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
WARNING:absl:Found untraced functions such as call_get_leaves while saving (showing 1 of 1). These functions will not be directly callable after loading.
[INFO kernel.cc:1176] Loading model from path intermediate_path/assets/ with prefix 983c5509ae744d96
[INFO decision_forest.cc:639] Model loaded with 500 root(s), 150490 node(s), and 6 input feature(s).
[INFO kernel.cc:1022] Use fast generic engine
WARNING:absl:Found untraced functions such as restored_function_body while saving (showing 1 of 1). These functions will not be directly callable after loading.
Time taken to save tfdf randomforest model 16692.85774230957
------------------------------
Converted model to TF-DF
------------------------------


------------------------------
Converting model to ONNX...
------------------------------
Time taken to convert onnx using hummingbird 4241.3012981414795
Time taken to write onnx model 67.10124015808105
------------------------------
Converted model to ONNX
------------------------------


------------------------------
Converting model to netsdb...
------------------------------
------------------------------
Converted model to netsdb
------------------------------


2022-09-11 18:38:23.565041: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/ubuntu/libtorch/lib:/home/ubuntu/libtorch/lib:
2022-09-11 18:38:23.565119: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2022-09-11 18:38:31.307481: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/ubuntu/libtorch/lib:/home/ubuntu/libtorch/lib:
2022-09-11 18:38:31.307530: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2022-09-11 18:38:31.307555: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-172-31-95-108): /proc/driver/nvidia/version does not exist
2022-09-11 18:38:31.307787: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
DATASET: tpcxai_fraud
MODEL: xgboost
FRAMEWORKS: pytorch,torch,tf-df,onnx,treelite,netsdb
------------------------------
Converting model to PyTorch...
------------------------------
Time Taken to convert HummingbirdPyTorch: 14971.274375915527
Time taken to save pytorch model 79.92291450500488
------------------------------
Converted model to PyTorch
------------------------------


------------------------------
Converting model to Torch...
------------------------------
Time taken to convert to torch using hummingbird 15679.136753082275
Time taken to save torch model 6.124258041381836
------------------------------
Converted model to Torch
------------------------------


------------------------------
Converting model to TF-DF...
------------------------------
XGBOOST_MODEL LEARNING RATE:
0.1
Use /tmp/tmpzdk9qd6q as temporary training directory
[INFO kernel.cc:1176] Loading model from path intermediate_path/tmp/ with prefix 11c5f40fb07c4091
[INFO kernel.cc:1028] Use slow generic engine
WARNING:tensorflow:AutoGraph could not transform <function simple_ml_inference_op_with_handle at 0x7f3f444fd0d0> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: could not get source code
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
WARNING:tensorflow:AutoGraph could not transform <function simple_ml_inference_op_with_handle at 0x7f3f444fd0d0> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: could not get source code
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
WARNING:absl:Found untraced functions such as call_get_leaves while saving (showing 1 of 1). These functions will not be directly callable after loading.
[INFO kernel.cc:1176] Loading model from path intermediate_path/assets/ with prefix 11c5f40fb07c4091
[INFO kernel.cc:1028] Use slow generic engine
WARNING:absl:Found untraced functions such as restored_function_body while saving (showing 1 of 1). These functions will not be directly callable after loading.
Time taken to save tfdf xgboost model 10761.487245559692
------------------------------
Converted model to TF-DF
------------------------------


------------------------------
Converting model to ONNX...
------------------------------
Time taken to convert onnx using hummingbird 4318.390846252441
Time taken to write onnx model 71.77233695983887
------------------------------
Converted model to ONNX
------------------------------


------------------------------
Converting model to TreeLite...
------------------------------
[18:38:40] ../src/compiler/ast_native.cc:711: Using ASTNativeCompiler
[18:38:40] ../src/compiler/ast/split.cc:29: Parallel compilation enabled; member trees will be divided into 8 translation units.
[18:38:41] ../src/c_api/c_api.cc:92: Code generation finished. Writing code to files...
[18:38:41] ../src/c_api/c_api.cc:97: Writing file tu6.c...
[18:38:41] ../src/c_api/c_api.cc:97: Writing file recipe.json...
[18:38:41] ../src/c_api/c_api.cc:97: Writing file tu5.c...
[18:38:41] ../src/c_api/c_api.cc:97: Writing file tu4.c...
[18:38:41] ../src/c_api/c_api.cc:97: Writing file tu3.c...
[18:38:41] ../src/c_api/c_api.cc:97: Writing file tu7.c...
[18:38:41] ../src/c_api/c_api.cc:97: Writing file header.h...
[18:38:41] ../src/c_api/c_api.cc:97: Writing file main.c...
[18:38:41] ../src/c_api/c_api.cc:97: Writing file tu0.c...
[18:38:41] ../src/c_api/c_api.cc:97: Writing file tu1.c...
[18:38:41] ../src/c_api/c_api.cc:97: Writing file tu2.c...
[18:38:41] /home/ubuntu/.local/lib/python3.9/site-packages/treelite/contrib/util.py:105: Compiling sources files in directory /home/ubuntu/netsdb/model-inference/decisionTree/experiments/models/tmppvd8qqcg into object files (*.o)...
[18:43:09] /home/ubuntu/.local/lib/python3.9/site-packages/treelite/contrib/util.py:135: Generating dynamic shared library /home/ubuntu/netsdb/model-inference/decisionTree/experiments/models/tmppvd8qqcg/predictor.so...
[18:43:09] /home/ubuntu/.local/lib/python3.9/site-packages/treelite/contrib/__init__.py:282: Generated shared library in 268.40 seconds
Time taken to convert and write treelite model 269230.25822639465
------------------------------
Converted model to TreeLite
------------------------------


------------------------------
Converting model to netsdb...
------------------------------
------------------------------
Converted model to netsdb
------------------------------


The maximum opset needed by this model is only 9.
DATASET: tpcxai_fraud
MODEL: lightgbm
FRAMEWORKS: pytorch,torch,onnx,treelite,lleaves,netsdb
------------------------------
Converting model to PyTorch...
------------------------------
Time Taken to convert HummingbirdPyTorch: 5823.574781417847
Time taken to save pytorch model 75.79326629638672
------------------------------
Converted model to PyTorch
------------------------------


------------------------------
Converting model to Torch...
------------------------------
Time taken to convert to torch using hummingbird 5827.1026611328125
Time taken to save torch model 6.085872650146484
------------------------------
Converted model to Torch
------------------------------


------------------------------
Converting model to ONNX...
------------------------------
Time taken to convert onnx using onnxmltools 8186.650514602661
Time taken to write onnx model 73.84252548217773
------------------------------
Converted model to ONNX
------------------------------


------------------------------
Converting model to TreeLite...
------------------------------
[18:45:46] ../src/compiler/ast_native.cc:711: Using ASTNativeCompiler
[18:45:46] ../src/compiler/ast/split.cc:29: Parallel compilation enabled; member trees will be divided into 8 translation units.
[18:45:47] ../src/c_api/c_api.cc:92: Code generation finished. Writing code to files...
[18:45:47] ../src/c_api/c_api.cc:97: Writing file tu6.c...
[18:45:47] ../src/c_api/c_api.cc:97: Writing file recipe.json...
[18:45:47] ../src/c_api/c_api.cc:97: Writing file tu5.c...
[18:45:47] ../src/c_api/c_api.cc:97: Writing file tu4.c...
[18:45:47] ../src/c_api/c_api.cc:97: Writing file tu3.c...
[18:45:47] ../src/c_api/c_api.cc:97: Writing file tu7.c...
[18:45:47] ../src/c_api/c_api.cc:97: Writing file header.h...
[18:45:47] ../src/c_api/c_api.cc:97: Writing file main.c...
[18:45:47] ../src/c_api/c_api.cc:97: Writing file tu0.c...
[18:45:47] ../src/c_api/c_api.cc:97: Writing file tu1.c...
[18:45:47] ../src/c_api/c_api.cc:97: Writing file tu2.c...
[18:45:47] /home/ubuntu/.local/lib/python3.9/site-packages/treelite/contrib/util.py:105: Compiling sources files in directory /home/ubuntu/netsdb/model-inference/decisionTree/experiments/models/tmpyg_teelz into object files (*.o)...
[18:51:39] /home/ubuntu/.local/lib/python3.9/site-packages/treelite/contrib/util.py:135: Generating dynamic shared library /home/ubuntu/netsdb/model-inference/decisionTree/experiments/models/tmpyg_teelz/predictor.so...
[18:51:39] /home/ubuntu/.local/lib/python3.9/site-packages/treelite/contrib/__init__.py:282: Generated shared library in 351.83 seconds
Time taken to convert and write treelite model 353152.0655155182
------------------------------
Converted model to TreeLite
------------------------------


------------------------------
Converting model to Lleaves...
------------------------------
Time taken to convert, compile and write Lleaves model 250755.82265853882
------------------------------
Converted model to Lleaves
------------------------------


------------------------------
Converting model to netsdb...
------------------------------
------------------------------
Converted model to netsdb
------------------------------


2022-09-11 18:56:10.264531: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/ubuntu/libtorch/lib:/home/ubuntu/libtorch/lib:
2022-09-11 18:56:10.264581: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2022-09-11 18:56:46.248732: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/ubuntu/libtorch/lib:/home/ubuntu/libtorch/lib:
2022-09-11 18:56:46.248784: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2022-09-11 18:56:46.248810: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-172-31-95-108): /proc/driver/nvidia/version does not exist
2022-09-11 18:56:46.249040: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
DATASET: tpcxai_fraud
MODEL: randomforest
FRAMEWORKS: pytorch,torch,tf-df,onnx,netsdb
------------------------------
Converting model to PyTorch...
------------------------------
Time Taken to convert HummingbirdPyTorch: 7527.962923049927
Time taken to save pytorch model 312.1349811553955
------------------------------
Converted model to PyTorch
------------------------------


------------------------------
Converting model to Torch...
------------------------------
Time taken to convert to torch using hummingbird 7038.259029388428
Time taken to save torch model 14.14799690246582
------------------------------
Converted model to Torch
------------------------------


------------------------------
Converting model to TF-DF...
------------------------------
Use /tmp/tmpajdl8ul_ as temporary training directory
[INFO kernel.cc:1176] Loading model from path intermediate_path/tmp/ with prefix f6f1d28719b545b8
[INFO decision_forest.cc:639] Model loaded with 1600 root(s), 479804 node(s), and 6 input feature(s).
[INFO abstract_model.cc:1246] Engine "RandomForestOptPred" built
[INFO kernel.cc:1022] Use fast generic engine
WARNING:tensorflow:AutoGraph could not transform <function simple_ml_inference_op_with_handle at 0x7fb030b761f0> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: could not get source code
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
WARNING:tensorflow:AutoGraph could not transform <function simple_ml_inference_op_with_handle at 0x7fb030b761f0> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: could not get source code
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
WARNING:absl:Found untraced functions such as call_get_leaves while saving (showing 1 of 1). These functions will not be directly callable after loading.
[INFO kernel.cc:1176] Loading model from path intermediate_path/assets/ with prefix f6f1d28719b545b8
[INFO decision_forest.cc:639] Model loaded with 1600 root(s), 479804 node(s), and 6 input feature(s).
[INFO kernel.cc:1022] Use fast generic engine
WARNING:absl:Found untraced functions such as restored_function_body while saving (showing 1 of 1). These functions will not be directly callable after loading.
Time taken to save tfdf randomforest model 41192.678928375244
------------------------------
Converted model to TF-DF
------------------------------


------------------------------
Converting model to ONNX...
------------------------------
Time taken to convert onnx using hummingbird 13942.18897819519
Time taken to write onnx model 223.85859489440918
------------------------------
Converted model to ONNX
------------------------------


------------------------------
Converting model to netsdb...
------------------------------
------------------------------
Converted model to netsdb
------------------------------


2022-09-11 18:59:40.730570: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/ubuntu/libtorch/lib:/home/ubuntu/libtorch/lib:
2022-09-11 18:59:40.730628: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2022-09-11 19:00:01.693555: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/ubuntu/libtorch/lib:/home/ubuntu/libtorch/lib:
2022-09-11 19:00:01.693605: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2022-09-11 19:00:01.693638: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-172-31-95-108): /proc/driver/nvidia/version does not exist
2022-09-11 19:00:01.693867: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
DATASET: tpcxai_fraud
MODEL: xgboost
FRAMEWORKS: pytorch,torch,tf-df,onnx,treelite,netsdb
------------------------------
Converting model to PyTorch...
------------------------------
Time Taken to convert HummingbirdPyTorch: 47822.58653640747
Time taken to save pytorch model 235.4269027709961
------------------------------
Converted model to PyTorch
------------------------------


------------------------------
Converting model to Torch...
------------------------------
Time taken to convert to torch using hummingbird 46527.95696258545
Time taken to save torch model 9.791374206542969
------------------------------
Converted model to Torch
------------------------------


------------------------------
Converting model to TF-DF...
------------------------------
XGBOOST_MODEL LEARNING RATE:
0.1
Use /tmp/tmpqyo3dtfa as temporary training directory
[INFO kernel.cc:1176] Loading model from path intermediate_path/tmp/ with prefix e9f902b9a03448f7
[INFO kernel.cc:1028] Use slow generic engine
WARNING:tensorflow:AutoGraph could not transform <function simple_ml_inference_op_with_handle at 0x7fe2de09d4c0> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: could not get source code
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
WARNING:tensorflow:AutoGraph could not transform <function simple_ml_inference_op_with_handle at 0x7fe2de09d4c0> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: could not get source code
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
WARNING:absl:Found untraced functions such as call_get_leaves while saving (showing 1 of 1). These functions will not be directly callable after loading.
[INFO kernel.cc:1176] Loading model from path intermediate_path/assets/ with prefix e9f902b9a03448f7
[INFO kernel.cc:1028] Use slow generic engine
WARNING:absl:Found untraced functions such as restored_function_body while saving (showing 1 of 1). These functions will not be directly callable after loading.
Time taken to save tfdf xgboost model 25995.03803253174
------------------------------
Converted model to TF-DF
------------------------------


------------------------------
Converting model to ONNX...
------------------------------
Time taken to convert onnx using hummingbird 14785.25447845459
Time taken to write onnx model 227.34665870666504
------------------------------
Converted model to ONNX
------------------------------


------------------------------
Converting model to TreeLite...
------------------------------
[19:00:23] ../src/compiler/ast_native.cc:711: Using ASTNativeCompiler
[19:00:23] ../src/compiler/ast/split.cc:29: Parallel compilation enabled; member trees will be divided into 8 translation units.
[19:00:25] ../src/c_api/c_api.cc:92: Code generation finished. Writing code to files...
[19:00:25] ../src/c_api/c_api.cc:97: Writing file tu6.c...
[19:00:25] ../src/c_api/c_api.cc:97: Writing file recipe.json...
[19:00:25] ../src/c_api/c_api.cc:97: Writing file tu5.c...
[19:00:25] ../src/c_api/c_api.cc:97: Writing file tu4.c...
[19:00:25] ../src/c_api/c_api.cc:97: Writing file tu3.c...
[19:00:25] ../src/c_api/c_api.cc:97: Writing file tu7.c...
[19:00:25] ../src/c_api/c_api.cc:97: Writing file header.h...
[19:00:25] ../src/c_api/c_api.cc:97: Writing file main.c...
[19:00:25] ../src/c_api/c_api.cc:97: Writing file tu0.c...
[19:00:25] ../src/c_api/c_api.cc:97: Writing file tu1.c...
[19:00:25] ../src/c_api/c_api.cc:97: Writing file tu2.c...
[19:00:25] /home/ubuntu/.local/lib/python3.9/site-packages/treelite/contrib/util.py:105: Compiling sources files in directory /home/ubuntu/netsdb/model-inference/decisionTree/experiments/models/tmpid3norlq into object files (*.o)...
[23:04:59] /home/ubuntu/.local/lib/python3.9/site-packages/treelite/contrib/util.py:135: Generating dynamic shared library /home/ubuntu/netsdb/model-inference/decisionTree/experiments/models/tmpid3norlq/predictor.so...
[23:05:00] /home/ubuntu/.local/lib/python3.9/site-packages/treelite/contrib/__init__.py:282: Generated shared library in 14674.41 seconds
Time taken to convert and write treelite model 14677154.324769974
------------------------------
Converted model to TreeLite
------------------------------


------------------------------
Converting model to netsdb...
------------------------------
------------------------------
Converted model to netsdb
------------------------------


The maximum opset needed by this model is only 9.
DATASET: tpcxai_fraud
MODEL: lightgbm
FRAMEWORKS: pytorch,torch,onnx,treelite,lleaves,netsdb
------------------------------
Converting model to PyTorch...
------------------------------
Time Taken to convert HummingbirdPyTorch: 20306.516408920288
Time taken to save pytorch model 237.4403476715088
------------------------------
Converted model to PyTorch
------------------------------


------------------------------
Converting model to Torch...
------------------------------
Time taken to convert to torch using hummingbird 18833.967685699463
Time taken to save torch model 10.89334487915039
------------------------------
Converted model to Torch
------------------------------


------------------------------
Converting model to ONNX...
------------------------------
Time taken to convert onnx using onnxmltools 26309.449434280396
Time taken to write onnx model 253.2212734222412
------------------------------
Converted model to ONNX
------------------------------


------------------------------
Converting model to TreeLite...
------------------------------
[23:26:02] ../src/compiler/ast_native.cc:711: Using ASTNativeCompiler
[23:26:03] ../src/compiler/ast/split.cc:29: Parallel compilation enabled; member trees will be divided into 8 translation units.
[23:26:06] ../src/c_api/c_api.cc:92: Code generation finished. Writing code to files...
[23:26:06] ../src/c_api/c_api.cc:97: Writing file tu6.c...
[23:26:06] ../src/c_api/c_api.cc:97: Writing file recipe.json...
[23:26:06] ../src/c_api/c_api.cc:97: Writing file tu5.c...
[23:26:06] ../src/c_api/c_api.cc:97: Writing file tu4.c...
[23:26:06] ../src/c_api/c_api.cc:97: Writing file tu3.c...
[23:26:06] ../src/c_api/c_api.cc:97: Writing file tu7.c...
[23:26:06] ../src/c_api/c_api.cc:97: Writing file header.h...
[23:26:06] ../src/c_api/c_api.cc:97: Writing file main.c...
[23:26:06] ../src/c_api/c_api.cc:97: Writing file tu0.c...
[23:26:06] ../src/c_api/c_api.cc:97: Writing file tu1.c...
[23:26:06] ../src/c_api/c_api.cc:97: Writing file tu2.c...
[23:26:06] /home/ubuntu/.local/lib/python3.9/site-packages/treelite/contrib/util.py:105: Compiling sources files in directory /home/ubuntu/netsdb/model-inference/decisionTree/experiments/models/tmpczpjaemt into object files (*.o)...
[04:05:38] /home/ubuntu/.local/lib/python3.9/site-packages/treelite/contrib/util.py:135: Generating dynamic shared library /home/ubuntu/netsdb/model-inference/decisionTree/experiments/models/tmpczpjaemt/predictor.so...
[04:05:39] /home/ubuntu/.local/lib/python3.9/site-packages/treelite/contrib/__init__.py:282: Generated shared library in 16773.50 seconds
Time taken to convert and write treelite model 16777639.395713806
------------------------------
Converted model to TreeLite
------------------------------


------------------------------
Converting model to Lleaves...
------------------------------
Time taken to convert, compile and write Lleaves model 1057226.3705730438
------------------------------
Converted model to Lleaves
------------------------------


------------------------------
Converting model to netsdb...
------------------------------
------------------------------
Converted model to netsdb
------------------------------


